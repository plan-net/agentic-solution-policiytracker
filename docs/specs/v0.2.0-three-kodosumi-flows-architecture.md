# Three Kodosumi Flows Architecture - v0.2.0 Todo List

## Overview
Transform the Political Monitoring Agent v0.2.0 into three independent Kodosumi deployable flows, each running on Ray cluster with proper form-based interfaces and Graphiti temporal knowledge graph integration.

## Architecture Goals
- **Flow 1**: Data Ingestion Flow - Document processing with Graphiti + communities
- **Flow 2**: Company Context Flow - Client-specific context management  
- **Flow 3**: Relevance Assessment Flow - Document analysis and scoring

## Flow 1: Data Ingestion Flow

### Form Requirements
- [ ] **Clear Data Option**: Checkbox to kill database and reset document tracking
  - When checked: Clear Neo4j database, reset Graphiti group, delete Azure tracking
  - When unchecked: Append only new documents (skip already processed)
- [ ] **Document Limit**: Integer field to limit documents processed per run
  - Default: 10
  - Min: 1, Max: 100
  - Validation with InputsError pattern
- [ ] **Community Creation**: Checkbox to enable community detection
  - Integrate Graphiti community algorithms
  - Store community metadata in Neo4j

### Technical Implementation
- [ ] Create `src/flows/data_ingestion/`
  - [ ] `app.py` - Kodosumi endpoint with rich form
  - [ ] `data_ingestion_analyzer.py` - Main entrypoint logic
  - [ ] `document_processor.py` - Core processing logic
  - [ ] `community_builder.py` - Community detection integration

### Form Model Design
```python
class DataIngestionInputs(F.Model):
    clear_data: bool = F.Field(default=False, description="Clear existing data before processing")
    document_limit: int = F.Field(default=10, ge=1, le=100, description="Maximum documents to process")
    enable_communities: bool = F.Field(default=True, description="Create document communities")
    source_path: str = F.Field(default="data/input/examples/", description="Path to input documents")
```

### Ray Tasks
- [ ] `@ray.remote` task for document processing with progress tracking
- [ ] `@ray.remote` task for community creation
- [ ] Progress streaming via tracer.markdown()
- [ ] Error handling with proper error.add() pattern

### Integration Points
- [ ] Graphiti Direct API with custom entity types
- [ ] Neo4j community storage and visualization
- [ ] Azure Storage for document tracking state
- [ ] Langfuse observability for processing metrics

## Flow 2: Company Context Flow

### Form Requirements
- [ ] **Company Selection**: Dropdown of existing companies from knowledge graph
- [ ] **Context Upload**: File upload for company-specific context documents
- [ ] **Industry Classification**: Multi-select for relevant regulatory domains
- [ ] **Geographic Scope**: Multi-select for jurisdictions of interest

### Technical Implementation
- [ ] Create `src/flows/company_context/`
  - [ ] `app.py` - Kodosumi endpoint
  - [ ] `company_context_analyzer.py` - Main entrypoint
  - [ ] `context_processor.py` - Context document processing
  - [ ] `profile_builder.py` - Company profile management

### Form Model Design
```python
class CompanyContextInputs(F.Model):
    company_name: str = F.Field(..., description="Company name or select existing")
    context_files: list[str] = F.Field(default=[], description="Context document paths")
    industries: list[str] = F.Field(default=[], description="Relevant industry classifications")
    jurisdictions: list[str] = F.Field(default=[], description="Geographic scope of operations")
    update_existing: bool = F.Field(default=True, description="Update existing company profile")
```

### Features
- [ ] Company entity creation/update in knowledge graph
- [ ] Context document ingestion with company linkage
- [ ] Industry and jurisdiction tagging
- [ ] Regulatory domain mapping

## Flow 3: Relevance Assessment Flow

### Form Requirements
- [ ] **Company Selection**: Dropdown from existing company profiles
- [ ] **Time Range**: Date range picker for temporal analysis
- [ ] **Assessment Type**: Radio buttons (Quick/Comprehensive/Custom)
- [ ] **Priority Threshold**: Slider for minimum relevance score
- [ ] **Export Format**: Checkbox options (JSON/Markdown/PDF)

### Technical Implementation
- [ ] Create `src/flows/relevance_assessment/`
  - [ ] `app.py` - Kodosumi endpoint
  - [ ] `relevance_analyzer.py` - Main entrypoint
  - [ ] `temporal_assessor.py` - Time-based relevance analysis
  - [ ] `report_generator.py` - Multi-format report generation

### Form Model Design
```python
class RelevanceAssessmentInputs(F.Model):
    company_name: str = F.Field(..., description="Target company for assessment")
    start_date: datetime = F.Field(..., description="Analysis start date")
    end_date: datetime = F.Field(default_factory=datetime.now, description="Analysis end date")
    assessment_type: str = F.Field(default="Quick", description="Assessment depth")
    priority_threshold: float = F.Field(default=0.7, ge=0.0, le=1.0, description="Minimum relevance score")
    export_formats: list[str] = F.Field(default=["markdown"], description="Output formats")
```

### Advanced Features
- [ ] Temporal relevance scoring using Graphiti time-aware queries
- [ ] Community-based impact analysis
- [ ] Regulatory change detection
- [ ] Predictive relevance modeling

## Shared Infrastructure

### Configuration Management
- [ ] Create shared `config/shared_config.yaml`
  - Graphiti connection settings
  - Neo4j database configuration
  - Azure Storage containers
  - Langfuse project settings
- [ ] Environment-specific overrides (dev/staging/prod)
- [ ] Config validation and error handling

### Folder Structure
```
src/
├── flows/
│   ├── __init__.py
│   ├── shared/
│   │   ├── __init__.py
│   │   ├── graphiti_client.py
│   │   ├── neo4j_client.py
│   │   ├── azure_client.py
│   │   └── base_models.py
│   ├── data_ingestion/
│   │   ├── __init__.py
│   │   ├── app.py
│   │   ├── data_ingestion_analyzer.py
│   │   ├── document_processor.py
│   │   └── community_builder.py
│   ├── company_context/
│   │   ├── __init__.py
│   │   ├── app.py
│   │   ├── company_context_analyzer.py
│   │   ├── context_processor.py
│   │   └── profile_builder.py
│   └── relevance_assessment/
│       ├── __init__.py
│       ├── app.py
│       ├── relevance_analyzer.py
│       ├── temporal_assessor.py
│       └── report_generator.py
```

### Shared Components
- [ ] `GraphitiClient` wrapper with connection pooling
- [ ] `Neo4jClient` with community and temporal query helpers
- [ ] `AzureStorageClient` with container management
- [ ] Base Pydantic models for entities and episodes
- [ ] Shared error handling and logging patterns

## Migration Tasks

### Legacy Code Cleanup
- [ ] Remove old v0.1.0 single-flow architecture
  - [ ] Archive `src/political_analyzer.py`
  - [ ] Archive `src/app.py` 
  - [ ] Archive `src/workflow/` (LangGraph approach)
  - [ ] Archive `src/analysis/` components
- [ ] Update pyproject.toml dependencies
- [ ] Clean up unused scripts in `/scripts/`

### Database Migration
- [ ] Create migration script for existing Graphiti data
- [ ] Preserve custom entity types and relationships
- [ ] Migrate to new community structure
- [ ] Update Neo4j schema for three-flow architecture

### Documentation Updates
- [ ] Update README.md with three-flow architecture
- [ ] Create individual flow documentation
- [ ] Update user guide with new workflow
- [ ] Document API endpoints and form interfaces

## Deployment Strategy

### Kodosumi Deployment Pattern
- [ ] Each flow as independent Kodosumi service
- [ ] Shared configuration via environment variables
- [ ] Ray cluster resource allocation per flow
- [ ] Health checks and monitoring for each service

### Development Workflow
- [ ] Flow-specific development commands in justfile
  - `just dev-ingestion`
  - `just dev-context` 
  - `just dev-assessment`
- [ ] Individual testing strategies per flow
- [ ] Integration testing across flows

### Production Considerations
- [ ] Flow dependency management (ingestion → context → assessment)
- [ ] Shared resource allocation (Neo4j, Graphiti, Azure)
- [ ] Monitoring and alerting per flow
- [ ] Error propagation and recovery strategies

## Success Criteria

### Flow 1 (Data Ingestion)
- [ ] Successfully process documents with clear data option
- [ ] Enforce document limits with proper validation
- [ ] Create communities and store in Neo4j
- [ ] Progress tracking via Kodosumi interface

### Flow 2 (Company Context)
- [ ] Dynamic company dropdown from knowledge graph
- [ ] Context document processing and linkage
- [ ] Industry/jurisdiction tagging and storage
- [ ] Company profile updates and versioning

### Flow 3 (Relevance Assessment)
- [ ] Temporal relevance analysis using Graphiti
- [ ] Multi-format report generation
- [ ] Priority threshold filtering
- [ ] Community-based impact scoring

### Integration Success
- [ ] All flows share common configuration
- [ ] Data flows seamlessly between components
- [ ] Performance meets requirements (< 30s per flow)
- [ ] Error handling provides clear user feedback

## Implementation Order

### Phase 1: Infrastructure (Week 1)
1. Create shared folder structure
2. Implement shared Graphiti/Neo4j clients
3. Set up configuration management
4. Create base Pydantic models

### Phase 2: Data Ingestion Flow (Week 1-2)
1. Implement form with clear data and document limit
2. Create Ray-based document processing
3. Integrate community creation
4. Test with example documents

### Phase 3: Company Context Flow (Week 2-3)
1. Implement company selection and context upload
2. Create context processing pipeline
3. Integrate industry/jurisdiction tagging
4. Test company profile management

### Phase 4: Relevance Assessment Flow (Week 3-4)
1. Implement temporal relevance analysis
2. Create multi-format report generation
3. Integrate community-based scoring
4. Test end-to-end assessment workflow

### Phase 5: Integration & Cleanup (Week 4)
1. Remove legacy v0.1.0 code
2. Complete documentation updates
3. Performance optimization
4. Final integration testing

## Risk Mitigation

### Technical Risks
- **Graphiti API Changes**: Pin to specific version (0.12.0rc1)
- **Ray Resource Conflicts**: Implement proper resource allocation
- **Neo4j Performance**: Optimize community queries and indexing
- **Form Validation**: Comprehensive input validation and error handling

### Business Risks
- **User Experience**: Maintain simple, intuitive interfaces
- **Data Loss**: Implement robust backup and recovery
- **Performance Degradation**: Monitor and optimize processing times
- **Integration Complexity**: Maintain clear separation of concerns

This architecture provides a scalable, maintainable foundation for the Political Monitoring Agent v0.2.0 with proper Kodosumi integration and temporal knowledge graph capabilities.